<?xml version="1.0" encoding="UTF-8" ?>
<!--  
    For information on how to customize this file, please see
    http://wiki.apache.org/solr/SolrConfigXml. The page also has a link to 
    an extensively commented version of this file. 
-->
<config>

  <luceneMatchVersion>6.0</luceneMatchVersion>
  <abortOnConfigurationError>${solr.abortOnConfigurationError:true}</abortOnConfigurationError>

  <schemaFactory class="ClassicIndexSchemaFactory"/>

  <lib dir="/cul/data/solr/instancelibs/bl1/"/>

  <dataDir>${solr.data.dir:}</dataDir>

  <indexConfig>
    <!-- maxFieldLength was removed in 4.0. To get similar behavior, include a 
         LimitTokenCountFilterFactory in your fieldType definition. E.g. 
     <filter class="solr.LimitTokenCountFilterFactory" maxTokenCount="10000"/>
    -->
    <!-- Maximum time to wait for a write lock (ms) for an IndexWriter. Default: 1000 -->
    <!-- <writeLockTimeout>1000</writeLockTimeout>  -->

    <!-- The maximum number of simultaneous threads that may be
         indexing documents at once in IndexWriter; if more than this
         many threads arrive they will wait for others to finish.
         Default in Solr/Lucene is 8. -->
    <!-- <maxIndexingThreads>8</maxIndexingThreads>  -->

    <!-- Expert: Enabling compound file will use less files for the index, 
         using fewer file descriptors on the expense of performance decrease. 
         Default in Lucene is "true". Default in Solr is "false" (since 3.6) -->
    <!-- <useCompoundFile>false</useCompoundFile> -->

    <!-- ramBufferSizeMB sets the amount of RAM that may be used by Lucene
         indexing for buffering added documents and deletions before they are
         flushed to the Directory.
         maxBufferedDocs sets a limit on the number of documents buffered
         before flushing.
         If both ramBufferSizeMB and maxBufferedDocs is set, then
         Lucene will flush based on whichever limit is hit first.  -->
    <!-- <ramBufferSizeMB>100</ramBufferSizeMB> -->
    <!-- <maxBufferedDocs>1000</maxBufferedDocs> -->

    <!-- Expert: Merge Policy 
         The Merge Policy in Lucene controls how merging of segments is done.
         The default since Solr/Lucene 3.3 is TieredMergePolicy.
         The default since Lucene 2.3 was the LogByteSizeMergePolicy,
         Even older versions of Lucene used LogDocMergePolicy.
      -->
    <!--
        <mergePolicy class="org.apache.lucene.index.TieredMergePolicy">
          <int name="maxMergeAtOnce">10</int>
          <int name="segmentsPerTier">10</int>
        </mergePolicy>
      -->
       
    <!-- Merge Factor
         The merge factor controls how many segments will get merged at a time.
         For TieredMergePolicy, mergeFactor is a convenience parameter which
         will set both MaxMergeAtOnce and SegmentsPerTier at once.
         For LogByteSizeMergePolicy, mergeFactor decides how many new segments
         will be allowed before they are merged into one.
         Default is 10 for both merge policies.
      -->
    <!-- 
    <mergeFactor>10</mergeFactor>
      -->

    <!-- Expert: Merge Scheduler
         The Merge Scheduler in Lucene controls how merges are
         performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
         can perform merges in the background using separate threads.
         The SerialMergeScheduler (Lucene 2.2 default) does not.
     -->
    <!-- 
       <mergeScheduler class="org.apache.lucene.index.ConcurrentMergeScheduler"/>
       -->

    <!-- LockFactory 

         This option specifies which Lucene LockFactory implementation
         to use.
      
         single = SingleInstanceLockFactory - suggested for a
                  read-only index or when there is no possibility of
                  another process trying to modify the index.
         native = NativeFSLockFactory - uses OS native file locking.
                  Do not use when multiple solr webapps in the same
                  JVM are attempting to share a single index.
         simple = SimpleFSLockFactory  - uses a plain file for locking

         Defaults: 'native' is default for Solr3.6 and later, otherwise
                   'simple' is the default

         More details on the nuances of each LockFactory...
         http://wiki.apache.org/lucene-java/AvailableLockFactories
    -->
    <!-- <lockType>native</lockType> -->

    <!-- Unlock On Startup

         If true, unlock any held write or commit locks on startup.
         This defeats the locking mechanism that allows multiple
         processes to safely access a lucene index, and should be used
         with care. Default is "false".

         This is not needed if lock type is 'none' or 'single'
     -->
    <!--
    <unlockOnStartup>false</unlockOnStartup>
      -->
    
    <!-- Expert: Controls how often Lucene loads terms into memory
         Default is 128 and is likely good for most everyone.
      -->
    <!-- <termIndexInterval>128</termIndexInterval> -->

    <!-- If true, IndexReaders will be reopened (often more efficient)
         instead of closed and then opened. Default: true
      -->
    <!-- 
    <reopenReaders>true</reopenReaders>
      -->

    <!-- Commit Deletion Policy

         Custom deletion policies can be specified here. The class must
         implement org.apache.lucene.index.IndexDeletionPolicy.

         http://lucene.apache.org/java/3_5_0/api/core/org/apache/lucene/index/IndexDeletionPolicy.html

         The default Solr IndexDeletionPolicy implementation supports
         deleting index commit points on number of commits, age of
         commit point and optimized status.
         
         The latest commit point should always be preserved regardless
         of the criteria.
    -->
    <!-- 
    <deletionPolicy class="solr.SolrDeletionPolicy">
    -->
      <!-- The number of commit points to be kept -->
      <!-- <str name="maxCommitsToKeep">1</str> -->
      <!-- The number of optimized commit points to be kept -->
      <!-- <str name="maxOptimizedCommitsToKeep">0</str> -->
      <!--
          Delete all commit points once they have reached the given age.
          Supports DateMathParser syntax e.g.
        -->
      <!--
         <str name="maxCommitAge">30MINUTES</str>
         <str name="maxCommitAge">1DAY</str>
      -->
    <!-- 
    </deletionPolicy>
    -->

    <!-- Lucene Infostream
       
         To aid in advanced debugging, Lucene provides an "InfoStream"
         of detailed information when indexing.

         Setting The value to true will instruct the underlying Lucene
         IndexWriter to write its debugging info the specified file
      -->
     <!-- <infoStream file="INFOSTREAM.txt">false</infoStream> --> 
  </indexConfig>

  <updateHandler class="solr.DirectUpdateHandler2" >
    <!-- Solr 4 introduces the Soft Commit option.  Soft Commit is like
         Auto Commit behavior except it enables/ensures that changes are
         visible.  However it does not ensure that data is synced to
         disk.  Of course this is faster and more Near-Realtime friendly -->
    <updateLog>
      <str name="dir">${solr.data.dir:}</str>
    </updateLog>  

    <!-- AutoCommit

         Perform a hard commit automatically under certain conditions.
         Instead of enabling autoCommit, consider using "commitWithin"
         when adding documents. 

         http://wiki.apache.org/solr/UpdateXmlMessages

         maxDocs - Maximum number of documents to add since the last
                   commit before automatically triggering a new commit.

         maxTime - Maximum amount of time in ms that is allowed to pass
                   since a document was added before automaticly
                   triggering a new commit. 
         openSearcher - if false, the commit causes recent index changes
           to be flushed to stable storage, but does not cause a new
           searcher to be opened to make those changes visible.

         If the updateLog is enabled, then it's highly recommended to
         have some sort of hard autoCommit to limit the log size.
      -->
     <autoCommit> 
       <maxTime>1200000</maxTime> 
       <openSearcher>false</openSearcher> 
     </autoCommit>

    <!-- softAutoCommit is like autoCommit except it causes a
         'soft' commit which only ensures that changes are visible
         but does not ensure that data is synced to disk.  This is
         faster and more near-realtime friendly than a hard commit.
      -->
     <!--
       <autoSoftCommit> 
         <maxTime>1000</maxTime> 
       </autoSoftCommit>
      -->
  </updateHandler>

  <!-- query time configurations -->
  <query>
    <maxBooleanClauses>1024</maxBooleanClauses>
    <filterCache class="solr.FastLRUCache"
        size="512" initialSize="512" autowarmCount="128"/>
    <queryResultCache class="solr.LRUCache"
        size="512" initialSize="512" autowarmCount="32"/>
    <documentCache class="solr.LRUCache"
        size="512" initialSize="512" autowarmCount="0"/>
    <enableLazyFieldLoading>true</enableLazyFieldLoading>
    <queryResultWindowSize>50</queryResultWindowSize>
    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
    <HashDocSet maxSize="3000" loadFactor="0.75"/>

    <!-- a newSearcher event is fired whenever a new searcher is being prepared
      and there is a current searcher handling requests (aka registered).
      It can be used to prime certain caches to prevent long request times for
      certain requests.
    -->
    <!-- QuerySenderListener takes an array of NamedList and executes a
         local query request for each NamedList in sequence. -->
    <listener event="newSearcher" class="solr.QuerySenderListener">
      <arr name="queries">
        <!-- query for all objects (default query) for home page facets -->
        <lst>
          <str name="rows">0</str> 
          <str name="fl">score</str>
        </lst>
        <!-- query for single document to populate filter cache -->
        <lst>
          <str name="q">id:00282214</str>
          <str name="qt">standard</str>
          <str name="rows">0</str>
          <str name="fl">score</str>
        </lst>
      </arr>
    </listener>

    <!-- a firstSearcher event is fired whenever a new searcher is being
         prepared but there is no current registered searcher to handle
         requests or to gain autowarming data from. -->
    <listener event="firstSearcher" class="solr.QuerySenderListener">
      <arr name="queries">
        <!-- query for all objects (default query) for home page facets -->
        <lst>
          <str name="rows">0</str> 
          <str name="fl">score</str>
        </lst>
        <!-- query for single document to populate filter cache -->
        <lst>
          <str name="q">id:00282214</str>
          <str name="qt">standard</str>
          <str name="rows">0</str>
          <str name="fl">score</str>
        </lst>
      </arr>
    </listener>

    <useColdSearcher>false</useColdSearcher>
    <maxWarmingSearchers>2</maxWarmingSearchers>
  </query>

  <requestDispatcher handleSelect="true" >
    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
    <httpCaching lastModifiedFrom="openTime" etagSeed="Solr" />
  </requestDispatcher>

  <requestHandler name="standard" class="solr.SearchHandler">
    <lst name="defaults">
      <str name="echoParams">all</str>
      <str name="q.op">AND</str>
    </lst>
  </requestHandler>

  <requestHandler name="/browse" class="solr.SearchHandler">
    <lst name="defaults">
      <str name="defType">lucene</str>
      <str name="echoParams">explicit</str>
      <str name="fl">
        heading,see,alternateForm,seeAlso,headingTypeDesc,notes,
        rda_json,counts_json,count,blacklightField,
        authority,mainEntry
      </str>
      <str name="df">headingSort</str>
      <str name="sort">headingSort asc,count desc</str>
      <str name="rows">20</str>
      <str name="wt">ruby</str>
      <str name="q">[&quot;$from&quot; TO *]</str>
      <str name="indent">true</str>
    </lst>
  </requestHandler>
  <requestHandler name="/reverse" class="solr.SearchHandler">
    <lst name="defaults">
      <str name="defType">lucene</str>
      <str name="echoParams">explicit</str>
      <str name="fl">
        heading,see,alternateForm,seeAlso,headingTypeDesc,notes,
        rda_json,counts_json,count,blacklightField,
        authority,mainEntry
      </str>
      <str name="df">headingSort</str>
      <str name="sort">headingSort desc,count asc</str>
      <str name="rows">20</str>
      <str name="wt">ruby</str>
      <str name="q">[* TO &quot;$to&quot;}</str>
      <str name="indent">true</str>
    </lst>
  </requestHandler>
  
  <!-- for requests to get a single document; use id=666 instead of q=id:666 -->
  <requestHandler name="document" class="solr.SearchHandler" >
    <lst name="defaults">
      <str name="echoParams">all</str>
      <str name="fl">*</str>
      <str name="rows">1</str>
      <str name="q">{!raw f=id v=$id}</str> <!-- use id=666 instead of q=id:666 -->
    </lst>
  </requestHandler>

 <!-- http://stackoverflow.com/questions/24570545/ -->
  <updateRequestProcessorChain name="skip-empty">
    <!--  Next two processors affect all fields - default configuration -->
    <processor class="TrimFieldUpdateProcessorFactory" /> <!--  Get rid of leading/trailing spaces. Also empties all-spaces fields for next filter-->
    <processor class="RemoveBlankFieldUpdateProcessorFactory" /> <!--  Delete fields with no content. More efficient and allows to query for presence/absence of field -->

    <processor class="solr.LogUpdateProcessorFactory" />
    <processor class="solr.RunUpdateProcessorFactory" />
  </updateRequestProcessorChain>

</config>
